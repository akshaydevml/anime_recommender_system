{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b052dc1-d5fd-47bb-85f3-a92fb7751d25",
   "metadata": {},
   "source": [
    "### The Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677a0dba-b391-4898-b639-7ec4ecbb3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, LoggingHandler, losses, models, util\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import faiss\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c5f2f-70b9-4af1-b80f-edab8e9a25be",
   "metadata": {},
   "source": [
    "### Load in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256f6da3-5876-4d9a-a5c3-abf66050d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('labels_with_pairs.csv')\n",
    "df['entry1'] = df['entry1'].astype(str)\n",
    "df['entry2'] = df['entry2'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f4227-2542-47cf-8898-7bf93901ef91",
   "metadata": {},
   "source": [
    "### Use the Sentence Transformers Input Example class to get it into the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b73ad06-e803-4ad5-9a95-e19ab4dfba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "for index, row in df.iterrows():\n",
    "    train_examples.append(InputExample(texts=[row['entry1'], row['entry2']], label=row['score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa22b87-369e-461f-9795-dffcb57d9632",
   "metadata": {},
   "source": [
    "### Define the model layers, loss function and set up Matryoshka Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26a3090-4a7e-4a34-850a-f41a65e5099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at Snowflake/snowflake-arctic-embed-m and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Snowflake/snowflake-arctic-embed-m\"\n",
    "num_epochs = 10\n",
    "model_save_path = (\n",
    "    \"output/matryoshka_sts_\" + model_name.replace(\"/\", \"-\") + \"-\" + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    ")\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "pooling_model = models.Pooling(\n",
    "    word_embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True,\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False,\n",
    ")\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "train_loss = losses.CoSENTLoss(model=model)\n",
    "train_loss = losses.MatryoshkaLoss(model, train_loss, [512,256,128,64])\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464dc7c3-9e7c-4a0d-b983-c36767777e4c",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d350abf0-5c31-42fb-a729-15c8b68b94dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.training_args:Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240824_175534-xne9mf1k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/akshaydevwandb/sentence-transformers/runs/xne9mf1k\" target=\"_blank\">checkpoints/model_2</a></strong> to <a href=\"https://wandb.ai/akshaydevwandb/sentence-transformers\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12850' max='12850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12850/12850 1:57:58, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>23.714800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>19.715700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>16.872100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>15.849200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>14.969800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>13.742600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>13.198500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>12.263700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>11.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>10.825600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>10.410800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>9.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>9.412400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>8.952200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>8.589400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>8.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>7.970600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>7.673200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>7.431900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>7.180900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>6.984800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>6.760400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>6.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>6.537000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>6.414000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92433947ac264073827b19bf85d7cd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:sentence_transformers.SentenceTransformer:Error while generating model card:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/sentence_transformers/SentenceTransformer.py\", line 1112, in _create_model_card\n",
      "    model_card = generate_model_card(self)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/sentence_transformers/model_card.py\", line 977, in generate_model_card\n",
      "    model_card = ModelCard.from_template(card_data=model.model_card_data, template_path=template_path, hf_emoji=\"🤗\")\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/repocard.py\", line 414, in from_template\n",
      "    return super().from_template(card_data, template_path, template_str, **template_kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/repocard.py\", line 324, in from_template\n",
      "    kwargs = card_data.to_dict().copy()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/sentence_transformers/model_card.py\", line 904, in to_dict\n",
      "    self.set_widget_examples(dataset)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/sentence_transformers/model_card.py\", line 420, in set_widget_examples\n",
      "    str_dataset = dataset[dataset_name].select_columns(columns)\n",
      "AttributeError: 'Dataset' object has no attribute 'select_columns'\n",
      "Consider opening an issue on https://github.com/UKPLab/sentence-transformers/issues with this traceback.\n",
      "Skipping model card creation.\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=50,\n",
    "    use_amp=True,\n",
    "    warmup_steps=warmup_steps,wandb\n",
    "    output_path=model_save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc9fc8-f331-4d93-9e7a-2e06ac2fc2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "query = 'world war 2 approaching'\n",
    "model_2 = SentenceTransformer('Snowflake/snowflake-arctic-embed-l')\n",
    "query_embedding = model.encode([query])\n",
    "sentences = [\n",
    "    df['entry2'].loc[0],\n",
    "    df['entry1'].loc[1],\n",
    "    \"This is the third sentence.\",\n",
    "]\n",
    "\n",
    "# Encode the sentences using the model\n",
    "sentences_embeddings = model.encode(sentences)\n",
    "\n",
    "# Compute cosine similarity between the query embedding and each sentence embedding\n",
    "cosine_scores = util.pytorch_cos_sim(query_embedding[:,:512], sentences_embeddings[:,:512])\n",
    "\n",
    "# Print the cosine similarity scores\n",
    "for i, score in enumerate(cosine_scores):\n",
    "    print(f\"Sentence {i+1}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46844844-3599-44dd-b782-9f3813af2333",
   "metadata": {},
   "source": [
    "## Create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26505c3-d391-4c2f-a0be-ad267e013070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61727b-efd6-4514-9f78-acb915a338e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63becc2b-1f06-43c1-9a10-0a787ff639eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45483b8-6101-4478-8d97-ac280f86cc91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28046c7e-b21a-415a-b5a9-88f39e2b5ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b008d-993e-4400-b907-7b9d20cb26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca0354-08b0-40f0-9f76-2ef75ad842ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
